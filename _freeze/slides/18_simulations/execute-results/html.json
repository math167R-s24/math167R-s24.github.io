{
  "hash": "493ffbdb92c1502f94326c6567a2ca91",
  "result": {
    "markdown": "---\ntitle: \"MATH167R: Simulations\"\nauthor: \"Peter Gao\"\nformat: \n  revealjs:\n    theme: [./slides.scss, ../theme.scss]\neditor: visual\n---\n\n\n## Overview of today\n\n-   Random variables in R\n-   The `r`, `p`, `d`, and `q` functions\n-   `replicate()`\n-   Writing simulations\n\n## Random variables in R\n\nWe have already seen a number of functions for generating random variables such as `sample()` and `rnorm()`.\n\nToday, we will expand on these functions and related functions for studying random variables and begin using them to write various simulations.\n\n## The `r`, `p`, `d`, and `q` functions\n\n1.  `rnorm()` can be used to generate `n` random observations from a normal distribution:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrnorm(n = 1, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.1332198\n```\n:::\n:::\n\n\n2.  `pnorm()` can be used to compute the distribution function at a value `q`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(q = 1, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8413447\n```\n:::\n:::\n\n\n3.  `qnorm()` can be used to compute the quantile function at a percentile `p`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqnorm(p = .75, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6744898\n```\n:::\n:::\n\n\n4.  `dnorm()` can be used to compute the density function at a value `x`:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndnorm(x = .5, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3520653\n```\n:::\n:::\n\n\n## Exercise\n\nSuppose we perform a two-sided hypothesis test using a normal distribution and obtain a z-score of 1.24. How would we compute the p-value?\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\n2 * (1 - pnorm(q = 1.24, mean = 0, sd = 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.2149754\n```\n:::\n:::\n\n\n. . .\n\nSuppose we perform a two-sided hypothesis test using a normal distribution and obtain a z-score of -2.12. How would we compute the p-value?\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\n2 * pnorm(q = 2.12, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.965994\n```\n:::\n:::\n\n\n## Random seeds\n\nRemember that `set.seed()` can be used to ensure that you obtain the same results each time you run your code.\n\nFor example, if you include the command `x <- rnorm(1)` in an .Rmd document with running `set.seed()`, each time you knit, you will produce a different value of `x`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1022)\nrnorm(n = 1, mean = 0, sd = 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] -0.6303919\n```\n:::\n:::\n\n\n## Monte Carlo methods\n\nMonte Carlo methods or Monte Carlo experiments use repeated random sampling to obtain numerical results or to approximate quantities of interest.\n\nMonte Carlo experiments are often used to:\n\n-   approximate integrals\n-   generate draws from a probability distribution\n-   optimize functions stochastically\n\n## Example: Transformations of random variables\n\nSuppose $X\\sim N(0, 1)$. What is $E(e^X)$?\n\nWe could use the change of variable formula to compute the expectation. Or we could use simulation to approximate this quantity. Asymptotic analysis is needed to study the convergence of our approximation.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_sim <- 1000\nn <- 100\nexp_X <- numeric(n_sim)\nfor (i in 1:n_sim) {\n  exp_X[i] <- exp(rnorm(n))\n}\nmean(exp_X)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.583819\n```\n:::\n:::\n\n\n## Example: Maximum of random variables\n\nSuppose $X_i\\sim \\mathrm{Exponential}(1)$ for $1\\leq i\\leq n$, for some $n$.\n\n-   What is $E(\\mathrm{max}(X_1,\\ldots, X_n))?$\n-   How does $E(\\mathrm{max}(X_1,\\ldots, X_n))$ change for different values of $n$?\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1022)\nn_sim <- 1000\nn <- 10\nmaxes <- numeric(n_sim)\nfor (i in 1:n_sim) {\n  maxes[i] <- max(rexp(n, rate = 1))\n}\nmean(maxes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.931317\n```\n:::\n:::\n\n\n. . .\n\nWhat about for $n=100$? Should the expected maximum be larger or smaller?\n\n## Example: Maximum of random variables\n\n\n::: {.cell}\n\n```{.r .cell-code}\nn_sim <- 1000\nn <- 100\nmaxes <- numeric(n_sim)\nfor (i in 1:n_sim) {\n  maxes[i] <- max(rexp(n, rate = 1))\n}\nmean(maxes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.133737\n```\n:::\n:::\n\n\n## `replicate()` for repeated evaluation\n\nIn the previous code, we have been using `for` loops, which explicitly and repeatedly change global variables.\n\nWe can alternatively use the `replicate()` function to repeatedly evaluate an expression and in particular to repeatedly generate data. The data will be automatically organized into a matrix or vector.\n\n## `replicate()` for repeated evaluation\n\nFor example, we can generate `n` exponential random variables and take their maximum:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nreplicate(10, rexp(10)) # matrix output\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            [,1]      [,2]      [,3]         [,4]       [,5]       [,6]\n [1,] 1.13043124 0.1479812 2.2223548 2.1268942156 2.39868030 0.14031279\n [2,] 0.55534004 1.9936832 1.5308543 0.3856013802 0.27843227 0.07257534\n [3,] 4.04774410 1.5802471 0.8427089 0.0285170421 0.08422752 0.16672644\n [4,] 0.95041912 1.2540541 2.3257087 1.2683416223 2.16567578 0.17816958\n [5,] 1.58876652 1.6758615 1.4261630 0.2769027893 0.74726688 0.17021181\n [6,] 1.99796987 2.0187209 2.4609051 0.2171987002 0.35444081 0.24326570\n [7,] 1.14231095 0.7548254 0.3966859 1.9520977567 0.15842032 1.31846979\n [8,] 0.02341325 1.8892792 2.2973738 0.3193784612 3.23298183 0.70573159\n [9,] 0.52699221 1.0601018 1.3775838 0.0007783933 1.68575293 0.21282549\n[10,] 0.02605074 1.1210718 7.7896914 0.9947959780 1.43672665 0.03251952\n            [,7]      [,8]       [,9]      [,10]\n [1,] 0.37598461 1.5698594 0.48767041 0.25788083\n [2,] 1.54188526 0.5463632 0.03341924 3.22056431\n [3,] 2.28019306 1.8544470 2.48718778 0.33689904\n [4,] 1.92829873 0.5781632 1.08695817 1.36571108\n [5,] 0.61021502 0.2839260 3.15368645 0.02273778\n [6,] 0.91375634 0.3061268 0.79635850 2.84436475\n [7,] 2.00932145 2.6931977 1.10894887 0.40095700\n [8,] 0.06227634 0.7167511 0.18378884 1.30463719\n [9,] 0.06959291 0.1803800 0.02571177 0.87495361\n[10,] 5.63161431 0.2733862 0.06480147 0.19743542\n```\n:::\n\n```{.r .cell-code}\nreplicate(10, max(rexp(10))) # vector output\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 2.084471 2.306936 3.248953 4.007540 1.415286 2.849782 2.835310 3.580029\n [9] 2.302169 1.573989\n```\n:::\n:::\n\n\n## `replicate()` for repeated evaluation\n\nUsing `replicate()`, the previous simulation is just:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmaxes <- replicate(1000, max(rexp(n)))\nmean(maxes)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.222014\n```\n:::\n:::\n\n\n## Example: Maximum of random variables\n\nWe can repeat this for many different values of `n`.\n\n\n::: {.cell hash='18_simulations_cache/revealjs/declarative.sim_0f69143a0b23e0be3bc6dbdf72505732'}\n\n```{.r .cell-code}\nn_sim <- 1000\nn_values <- c(10, 25, 50, 100, 250, 500, 1000)\nmax_by_n <- c()\nfor (n in n_values) {\n  maxes <- numeric(n_sim)\n  for (i in 1:n_sim) {\n    maxes[i] <- max(rexp(n, rate = 1))\n  }\n  max_by_n <- c(max_by_n, mean(maxes))\n}\nmax_by_n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.905734 3.905639 4.506815 5.230620 6.083090 6.807637 7.503720\n```\n:::\n:::\n\n\n## Example: Maximum of random variables\n\nNote that we can write the maximum of exponentials simulation using `replicate()`:\n\n\n::: {.cell hash='18_simulations_cache/revealjs/functional.sim_1c928e672bb842e67a4a76513944ece5'}\n\n```{.r .cell-code}\nmax_by_n <- vapply(\n  n_values, \n  function(n) mean(replicate(n_sim, max(rexp(n, rate = 1)))), \n  numeric(1)\n)\nmax_by_n\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.926930 3.808266 4.520613 5.221548 6.116823 6.740582 7.425483\n```\n:::\n:::\n\n\n## Example: Maximum of random variables\n\nIt turns out that $\\mathrm{max}(X_1,\\ldots, X_n)$ can be modeled using a Gumbel distribution (after being transformed). Below, we plot the empirical mean and approximate the theoretical expectation (for large $n$).\n\n\n::: {.cell hash='18_simulations_cache/revealjs/plot_results_97f2b61b33126d51276c25bf2d91c3f9'}\n\n```{.r .cell-code}\nplot(n_values, max_by_n,\n     type = \"l\",\n     xlab = \"n\", ylab = \"Maximum\",\n     main = paste0(\"Sample mean of maximums (black)\",\n                   \"and theoretical expectation (red)\"))\nlines(n_values, -digamma(1) + log(n_values), col = \"red\")\n```\n\n::: {.cell-output-display}\n![](18_simulations_files/figure-revealjs/plot_results-1.png){width=960}\n:::\n:::\n\n\n## Random walks\n\nRandom walks are stochastic processes that describe a sequence of random steps on some space.\n\nA simple example is the one-dimensional random walk on the integer number line which starts at 0 and for each step, moves forward (+1) or backward (-1) with equal probability.\n\n## Random walks\n\nWe can easily simulate a one-dimensional random walk:\n\n\n::: {.cell hash='18_simulations_cache/revealjs/random_walk_9c108e2fb0c84593d2be5104fa89a289'}\n\n```{.r .cell-code}\nset.seed(123)\nn_steps <- 100\nx <- numeric(n_steps)\nx[1] <- 0\nfor (i in 2:n_steps) {\n  x[i] <- x[i - 1] + sample(c(1, -1), 1)\n}\n```\n:::\n\n\n. . . We can then plot our results\n\n\n::: {.cell hash='18_simulations_cache/revealjs/random_walk_plot_5bfd322c9ce02495373a4b9e242aee20'}\n\n```{.r .cell-code}\nplot(1:n_steps, x, type = \"l\",\n     xlab = \"Step\", ylab = \"x\",\n     main = \"A one-dimensional random walk\")\n```\n\n::: {.cell-output-display}\n![](18_simulations_files/figure-revealjs/random_walk_plot-1.png){width=960}\n:::\n:::\n\n\n## A more functional version with recursion\n\nWe can also adopt a more functional approach:\n\n\n::: {.cell hash='18_simulations_cache/revealjs/random_walk_functional_66de4887a0ced08b5f4f0233108655e7'}\n\n```{.r .cell-code}\ntake_step <- function() {\n  return(sample(c(1, -1), 1))\n}\nwalk_randomly <- function(n_steps, start = 0) {\n  if (n_steps <= 1) {\n    return(start)\n  }\n  x <- c(start, walk_randomly(n_steps - 1, start + take_step()))\n  return(x)\n}\nplot(1:100, walk_randomly(100), type = \"l\",\n     xlab = \"Step\", ylab = \"x\",\n     main = \"A one-dimensional random walk\")\n```\n\n::: {.cell-output-display}\n![](18_simulations_files/figure-revealjs/random_walk_functional-1.png){width=960}\n:::\n:::\n\n\n## A two-dimensional random walk\n\nA two-dimensional random walk takes place on the integer grid, where at each step, we can either walk north, south, east, or west.\n\n\n::: {.cell hash='18_simulations_cache/revealjs/2d_random_walk_functional_1a8be4fa21db15f8d3c91b1e69e188b7'}\n\n```{.r .cell-code}\ntake_step_2d <- function() {\n  steps <- rbind(c(0, 1),\n                 c(0, -1), \n                 c(1, 0),\n                 c(-1, 0))\n  return(steps[sample(1:4, 1), ])\n}\nwalk_randomly_2d <- function(n_steps, start = c(0, 0)) {\n  if (n_steps <= 1) {\n    return(start)\n  }\n  x <- rbind(start, walk_randomly_2d(n_steps - 1, start + take_step_2d()))\n  rownames(x) <- NULL\n  return(x)\n}\nn_steps <- 100\ncoords <- walk_randomly_2d(n_steps)\ncoords\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       [,1] [,2]\n  [1,]    0    0\n  [2,]    0    1\n  [3,]   -1    1\n  [4,]   -1    0\n  [5,]   -1   -1\n  [6,]   -2   -1\n  [7,]   -2    0\n  [8,]   -3    0\n  [9,]   -4    0\n [10,]   -4   -1\n [11,]   -3   -1\n [12,]   -4   -1\n [13,]   -5   -1\n [14,]   -6   -1\n [15,]   -5   -1\n [16,]   -5    0\n [17,]   -6    0\n [18,]   -7    0\n [19,]   -8    0\n [20,]   -8   -1\n [21,]   -8    0\n [22,]   -8   -1\n [23,]   -7   -1\n [24,]   -8   -1\n [25,]   -7   -1\n [26,]   -7    0\n [27,]   -6    0\n [28,]   -7    0\n [29,]   -7   -1\n [30,]   -7    0\n [31,]   -7    1\n [32,]   -7    0\n [33,]   -6    0\n [34,]   -6    1\n [35,]   -6    0\n [36,]   -6   -1\n [37,]   -6    0\n [38,]   -7    0\n [39,]   -8    0\n [40,]   -9    0\n [41,]   -9   -1\n [42,]  -10   -1\n [43,]  -10    0\n [44,]  -10    1\n [45,]  -10    0\n [46,]  -10    1\n [47,]  -11    1\n [48,]  -10    1\n [49,]  -10    2\n [50,]  -10    3\n [51,]  -11    3\n [52,]  -12    3\n [53,]  -12    2\n [54,]  -12    3\n [55,]  -13    3\n [56,]  -13    2\n [57,]  -13    3\n [58,]  -13    4\n [59,]  -13    5\n [60,]  -12    5\n [61,]  -11    5\n [62,]  -11    4\n [63,]  -11    5\n [64,]  -12    5\n [65,]  -12    4\n [66,]  -13    4\n [67,]  -12    4\n [68,]  -12    3\n [69,]  -11    3\n [70,]  -11    2\n [71,]  -10    2\n [72,]  -10    3\n [73,]  -10    4\n [74,]  -10    5\n [75,]  -10    6\n [76,]   -9    6\n [77,]   -9    5\n [78,]   -9    6\n [79,]   -9    5\n [80,]   -9    6\n [81,]   -8    6\n [82,]   -7    6\n [83,]   -7    7\n [84,]   -8    7\n [85,]   -8    6\n [86,]   -7    6\n [87,]   -7    7\n [88,]   -6    7\n [89,]   -6    6\n [90,]   -7    6\n [91,]   -8    6\n [92,]   -8    7\n [93,]   -9    7\n [94,]   -9    8\n [95,]   -9    9\n [96,]   -9   10\n [97,]   -9   11\n [98,]   -8   11\n [99,]   -8   10\n[100,]   -8    9\n```\n:::\n:::\n\n\n## A two-dimensional random walk\n\nWe can use `geom_path()` to illustrate the path taken by the random walker:\n\n\n::: {.cell hash='18_simulations_cache/revealjs/2d_random_walk_functional_plot_b8ddf83442018476579b91a1ec3ca782'}\n\n```{.r .cell-code}\nlibrary(ggplot2)\ncoords_dat <- data.frame(x = coords[, 1],\n                         y = coords[, 2],\n                         step = 1:n_steps)\nggplot(coords_dat, aes(x = x, y = y, color = step)) + geom_path()\n```\n\n::: {.cell-output-display}\n![](18_simulations_files/figure-revealjs/2d_random_walk_functional_plot-1.png){width=960}\n:::\n:::\n\n::: {.cell}\n\n:::\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}