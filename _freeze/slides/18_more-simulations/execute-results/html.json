{
  "hash": "0cc0d18b1ca6c5f4200afa470ca93a83",
  "result": {
    "markdown": "---\ntitle: \"MATH167R: Simulations\"\nauthor: \"Peter Gao\"\nformat: \n  revealjs:\n    theme: [./slides.scss, ../theme.scss]\neditor: visual\n---\n\n\n## Overview of today\n\n-   Simulations continued\n-   Timing code\n\n## Warm up: Estimating $\\pi$\n\nThe area of a radius $r$ circle is $\\pi r^2$. How could we use simulation to estimate $\\pi$?\n\n. . .\n\nHint: what if we randomly generated points on a square?\n\n. . .\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nlibrary(ggplot2)\nrandom_points <- data.frame(x = runif(500, -1, 1),\n                            y = runif(500, -1, 1))\nrandom_points <- random_points |>\n  mutate(in_circle = x^2 + y^2 < 1)\nggplot(random_points, aes(x = x, y = y, color = in_circle)) + \n  geom_point() +\n  theme(aspect.ratio=1)\n```\n:::\n\n\n## Warm up: Estimating $\\pi$\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/random_points_1_8e7e40799fd9198fa079f3390959f1fe'}\n::: {.cell-output-display}\n![](18_more-simulations_files/figure-revealjs/random_points_1-1.png){width=960}\n:::\n:::\n\n\n## Warm up: Estimating $\\pi$\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/random_points_425063fdb6ffed3243d497a9a0b06835'}\n\n```{.r .cell-code}\nrandom_points <- data.frame(x = runif(500, -1, 1),\n                            y = runif(500, -1, 1))\nrandom_points <- random_points |>\n  mutate(in_circle = x^2 + y^2 < 1)\nrandom_points |> summarize(pi_est = 4 * mean(in_circle))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  pi_est\n1  3.144\n```\n:::\n:::\n\n\n## Random walks\n\nRandom walks are stochastic processes that describe a sequence of random steps on some space.\n\nA simple example is the one-dimensional random walk on the integer number line which starts at 0 and for each step, moves forward (+1) or backward (-1) with equal probability.\n\n## Random walks\n\nWe can simulate a one-dimensional random walk:\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/random_walk_fb6d12257ddf96fdbae4c8218aee0ff6'}\n\n```{.r .cell-code}\nset.seed(123)\nn_steps <- 100\nx <- numeric(n_steps)\nx[1] <- 0\nfor (i in 2:n_steps) {\n  x[i] <- x[i - 1] + sample(c(1, -1), 1)\n}\n```\n:::\n\n\n## Random walks\n\nWe can then plot our results:\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/random_walk_plot_7c5f66019ceecda4873cc30ebb602f64'}\n\n```{.r .cell-code}\nplot(1:n_steps, x, type = \"l\",\n     xlab = \"Step\", ylab = \"x\",\n     main = \"A one-dimensional random walk\")\n```\n\n::: {.cell-output-display}\n![](18_more-simulations_files/figure-revealjs/random_walk_plot-1.png){width=960}\n:::\n:::\n\n\n## A more functional version with recursion\n\nWe can also adopt a more functional approach:\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/random_walk_functional_d66df8796bcb6156786c64845724d0aa'}\n\n```{.r .cell-code}\ntake_step <- function() {\n  return(sample(c(1, -1), 1))\n}\nwalk_randomly <- function(n_steps, start = 0) {\n  if (n_steps <= 1) {\n    return(start)\n  }\n  x <- c(start, \n         walk_randomly(n_steps - 1, start + take_step()))\n  return(x)\n}\n```\n:::\n\n\n## A more functional version with recursion\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/random_walk_functional_plot_ea3a05175423579cd34206ea838b2f70'}\n\n```{.r .cell-code}\nplot(1:100, walk_randomly(100), type = \"l\",\n     xlab = \"Step\", ylab = \"x\",\n     main = \"A one-dimensional random walk\")\n```\n\n::: {.cell-output-display}\n![](18_more-simulations_files/figure-revealjs/random_walk_functional_plot-1.png){width=960}\n:::\n:::\n\n\n## A two-dimensional random walk\n\nA two-dimensional random walk takes place on the integer grid, where at each step, we can either walk north, south, east, or west.\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/2d_random_walk_functional_17a91c5c768da7afc3e696ddd782c56a'}\n\n```{.r .cell-code}\ntake_step_2d <- function() {\n  steps <- rbind(c(0, 1),\n                 c(0, -1), \n                 c(1, 0),\n                 c(-1, 0))\n  return(steps[sample(1:4, 1), ])\n}\nwalk_randomly_2d <- function(n_steps, start = c(0, 0)) {\n  if (n_steps <= 1) {\n    return(start)\n  }\n  x <- rbind(start, \n             walk_randomly_2d(n_steps - 1, start + take_step_2d()))\n  rownames(x) <- NULL\n  return(x)\n}\n```\n:::\n\n\n## A two-dimensional random walk\n\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n```\n       [,1] [,2]\n  [1,]    0    0\n  [2,]    0    1\n  [3,]   -1    1\n  [4,]   -1    0\n  [5,]   -1   -1\n  [6,]   -2   -1\n  [7,]   -2    0\n  [8,]   -3    0\n  [9,]   -4    0\n [10,]   -4   -1\n [11,]   -3   -1\n [12,]   -4   -1\n [13,]   -5   -1\n [14,]   -6   -1\n [15,]   -5   -1\n [16,]   -5    0\n [17,]   -6    0\n [18,]   -7    0\n [19,]   -8    0\n [20,]   -8   -1\n [21,]   -8    0\n [22,]   -8   -1\n [23,]   -7   -1\n [24,]   -8   -1\n [25,]   -7   -1\n [26,]   -7    0\n [27,]   -6    0\n [28,]   -7    0\n [29,]   -7   -1\n [30,]   -7    0\n [31,]   -7    1\n [32,]   -7    0\n [33,]   -6    0\n [34,]   -6    1\n [35,]   -6    0\n [36,]   -6   -1\n [37,]   -6    0\n [38,]   -7    0\n [39,]   -8    0\n [40,]   -9    0\n [41,]   -9   -1\n [42,]  -10   -1\n [43,]  -10    0\n [44,]  -10    1\n [45,]  -10    0\n [46,]  -10    1\n [47,]  -11    1\n [48,]  -10    1\n [49,]  -10    2\n [50,]  -10    3\n [51,]  -11    3\n [52,]  -12    3\n [53,]  -12    2\n [54,]  -12    3\n [55,]  -13    3\n [56,]  -13    2\n [57,]  -13    3\n [58,]  -13    4\n [59,]  -13    5\n [60,]  -12    5\n [61,]  -11    5\n [62,]  -11    4\n [63,]  -11    5\n [64,]  -12    5\n [65,]  -12    4\n [66,]  -13    4\n [67,]  -12    4\n [68,]  -12    3\n [69,]  -11    3\n [70,]  -11    2\n [71,]  -10    2\n [72,]  -10    3\n [73,]  -10    4\n [74,]  -10    5\n [75,]  -10    6\n [76,]   -9    6\n [77,]   -9    5\n [78,]   -9    6\n [79,]   -9    5\n [80,]   -9    6\n [81,]   -8    6\n [82,]   -7    6\n [83,]   -7    7\n [84,]   -8    7\n [85,]   -8    6\n [86,]   -7    6\n [87,]   -7    7\n [88,]   -6    7\n [89,]   -6    6\n [90,]   -7    6\n [91,]   -8    6\n [92,]   -8    7\n [93,]   -9    7\n [94,]   -9    8\n [95,]   -9    9\n [96,]   -9   10\n [97,]   -9   11\n [98,]   -8   11\n [99,]   -8   10\n[100,]   -8    9\n```\n:::\n:::\n\n\n## A two-dimensional random walk\n\nWe can use `geom_path()` to illustrate the path taken by the random walker:\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/2d_random_walk_functional_plot_b8ee5a2c19ccc82903141791cbc519e8'}\n\n```{.r .cell-code}\nlibrary(ggplot2)\ncoords_dat <- data.frame(x = coords[, 1],\n                         y = coords[, 2],\n                         step = 1:n_steps)\nggplot(coords_dat, aes(x = x, y = y, color = step)) +\n  geom_path()\n```\n\n::: {.cell-output-display}\n![](18_more-simulations_files/figure-revealjs/2d_random_walk_functional_plot-1.png){width=960}\n:::\n:::\n\n\n## A two-dimensional random walk\n\nWe can use the `gganimate` package to animate our visualization:\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/2d_random_walk_functional_anim_23650307ee002e617845645b89ee1fab'}\n\n```{.r .cell-code}\nlibrary(gganimate)\nanim_walk <- ggplot(coords_dat, aes(x = x, y = y, color = step)) +\n  geom_path() +\n  transition_reveal(along = step)\nanim_walk\n```\n\n::: {.cell-output-display}\n![](18_more-simulations_files/figure-revealjs/2d_random_walk_functional_anim-1.gif)\n:::\n:::\n\n\n## Random walks continued\n\nReturn to the code for a one-dimensional random walk:\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/unnamed-chunk-2_3a3db262f460d398ac2be4d695960191'}\n\n```{.r .cell-code}\ntake_step <- function() {\n  # move forwards or backwards with equal probability\n  return(sample(c(1, -1), 1))\n}\nwalk_randomly <- function(n_steps, start = 0) {\n  if (n_steps <= 1) {\n    return(start)\n  }\n  x <- c(start, walk_randomly(n_steps - 1, start + take_step()))\n  return(x)\n}\nplot(1:100, walk_randomly(100), type = \"l\",\n     xlab = \"Step\", ylab = \"x\",\n     main = \"A one-dimensional random walk\")\n```\n:::\n\n\n## Random walks continued\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/redux_013a5d870a160277353b640d03ec74f8'}\n::: {.cell-output-display}\n![](18_more-simulations_files/figure-revealjs/redux-1.png){width=960}\n:::\n:::\n\n\n## Random walks continued\n\nWe can use this simulation code to estimate a number of properties about random walks, including:\n\n1.  If we consider a random walk of length $n$, how often will the walker visit $x=0$, on average?\n\n2.  If we consider a random walk of length $n$, how often will the walker visit $x=10$, on average?\n\n3.  The walker starts at $x=0$. What is the expected length of time before the walker returns to $x=0$ (if it is finite)?\n\n4.  What is the expected maximum value of $|x_i|$ for a random walk of length $n$?\n\n## Random walks continued\n\n*If we consider a random walk of length* $n$, how often will the walker visit $x=0$, on average?\n\nConsider that the results of `walk_randomly(n_steps)` is a vector of length `n_steps`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nwalk_randomly(20)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  0  1  2  3  2  3  2  1  0  1  2  1  0 -1  0 -1  0 -1  0  1\n```\n:::\n:::\n\n\n. . .\n\nWe need an expression to count the number of times we reach $x=0$ (minus the start).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nsum(walk_randomly(20) == 0) - 1\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5\n```\n:::\n:::\n\n\n## Random walks continued\n\n*If we consider a random walk of length* $n$, how often will the walker visit $x=0$, on average?\n\nNow we can use `replicate()` to repeatedly evaluate our expression and then take the mean:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(123)\nmean(replicate(10000, sum(walk_randomly(20) == 0) - 1))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.518\n```\n:::\n:::\n\n\n## Varying `n_steps` parameter\n\n*If we consider a random walk of length* $n$, how often will the walker visit $x=0$, on average?\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/varying_n_steps_47960fc6a3fea8f443cdd1b85daa1327'}\n\n```{.r .cell-code}\nset.seed(123)\nns <- c(10, 20, 50, 100, 200, 500, 1000) \nexpected_returns <- \n  vapply(ns, \n         function(n_steps) \n           mean(replicate(1000, sum(walk_randomly(n_steps) == 0) - 1)),\n         numeric(1))\nplot(ns, expected_returns, type = \"l\", \n     xlab = \"Number of steps\", \n     ylab = \"Mean returns to x = 0\")\n```\n:::\n\n\n## Varying `n_steps` parameter\n\n*If we consider a random walk of length* $n$, how often will the walker visit $x=0$, on average?\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/varying_n_steps2_dbbd94d0511afcd77563d0969bcef315'}\n::: {.cell-output-display}\n![](18_more-simulations_files/figure-revealjs/varying_n_steps2-1.png){width=960}\n:::\n:::\n\n\n## Random walks continued\n\nHow could we adapt this code to answer the question:\n\n*If we consider a random walk of length* $n$, how often will the walker visit $x=10$, on average?\n\nAs $n\\rightarrow\\infty$, how will the expected number of visits to $x=10$ before step $n$ change?\n\n## Random walks continued\n\n*If we consider a random walk of length* $n$, how often will the walker visit $x=10$, on average?\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/varying_n_steps_10_acd156f26db65d9ebc2aa7c65edd0399'}\n\n```{.r .cell-code}\nset.seed(123)\nns <- c(10, 20, 50, 100, 200, 500, 1000) \nexpected_returns <- \n  vapply(ns, \n         function(n_steps) \n           mean(replicate(1000, sum(walk_randomly(n_steps) == 10))),\n         numeric(1))\nplot(ns, expected_returns, type = \"l\", \n     xlab = \"Number of steps\", \n     ylab = \"Mean visits to x = 10\")\n```\n:::\n\n\n## Random walks continued\n\n*If we consider a random walk of length* $n$, how often will the walker visit $x=10$, on average?\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/varying_n_steps_102_577663927c6e91f02ac2589d82a2dd1e'}\n::: {.cell-output-display}\n![](18_more-simulations_files/figure-revealjs/varying_n_steps_102-1.png){width=960}\n:::\n:::\n\n\n## Expected time of return\n\nCan we adapt this code to answer the following question?\n\n*The walker starts at* $x=0$. What is the expected length of time before the walker returns to $x=0$ (if it is finite)?\n\nWe have to be a little clever here--we only ever compute a finite-length random walk.\n\nFor any nonnegative integer valued random variable $X$,\n\n$$E(X)=\\sum_{n = 1}^\\infty P(X>n)$$\n\n## Expected time of return\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/expected_return_41d36a43213f2085389c4938db8ac5b6'}\n\n```{.r .cell-code}\nset.seed(123)\nns <- 1:20\n# for each n, estimate the proportion of random walks that do NOT return\n# to zero, using simulations\nproportion_no_returns <- \n  vapply(ns, \n         function(n_steps) \n           mean(replicate(2500, sum(walk_randomly(n_steps) == 0) < 2)),\n         numeric(1))\nplot(ns, proportion_no_returns, type = \"l\", \n     xlab = \"Number of steps\", \n     ylab = \"Mean visits to x = 10\")\nproportion_no_returns\n```\n:::\n\n\n## Expected time of return\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/expected_return2_1030adf14e388fc00615b256e9b8e50d'}\n::: {.cell-output-display}\n![](18_more-simulations_files/figure-revealjs/expected_return2-1.png){width=960}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 1.0000 1.0000 0.5080 0.4828 0.3720 0.3704 0.3308 0.3036 0.2836 0.2700\n[11] 0.2336 0.2504 0.2136 0.2340 0.2140 0.2084 0.1944 0.2196 0.1944 0.1784\n```\n:::\n:::\n\n\n## Expected time of return\n\nDoes the infinite series converge?\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/partial_sums_2b0dae7e4ffd98193401cefa73372052'}\n\n```{.r .cell-code}\n# calculate partial sums of the infinite series\ncumsum(proportion_no_returns)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 1.0000 2.0000 2.5080 2.9908 3.3628 3.7332 4.0640 4.3676 4.6512 4.9212\n[11] 5.1548 5.4052 5.6188 5.8528 6.0668 6.2752 6.4696 6.6892 6.8836 7.0620\n```\n:::\n:::\n\n\n## Expected time of return\n\n*The walker starts at* $x=0$. What is the expected length of time before the walker returns to $x=0$ (if it is finite)?\n\nIt turns out the expected length of time is infinite--a key example of why we have to be careful about using simulations to replace mathematical analysis.\n\n## Exercise\n\nHow would we write a simulation to answer the following question:\n\n*What is the expected maximum value of* $|x_i|$ for a random walk of length $n$?\n\n## Timing code\n\nWhen running simulations, the number of different dimensions we consider (number of simulations, number of steps, etc.) can rapidly increase computational cost.\n\nWe often may want to be able to estimate the runtime of our simulations or to compare the speed of various versions of a simulation.\n\n**Example**: Which is faster: vectorized code or a for loop?\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/example_vec_52e92f694d855fded8ecad789087a1c8'}\n\n```{.r .cell-code}\n# vectorized\nx_vec <- rnorm(100000) + 1\n\n# for loop\nx_for <- numeric()\nfor (i in 1:100000){\n  x_for[i] <- rnorm(1) + 1\n}\n```\n:::\n\n\n## `Sys.time()`\n\nThe `Sys.time()` function can be used to report the time at evaluation.\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/systime_fe8e00a89f5c0876f1a2c3d0390b26ee'}\n\n```{.r .cell-code}\nstart_time <- Sys.time()\nx_vec <- rnorm(100000) + 1\nprint(Sys.time() - start_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime difference of 0.003158092 secs\n```\n:::\n\n```{.r .cell-code}\nstart_time <- Sys.time()\nx_for <- numeric()\nfor (i in 1:100000){\n  x_for[i] <- rnorm(1) + 1\n}\nprint(Sys.time() - start_time)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nTime difference of 0.1249311 secs\n```\n:::\n:::\n\n\n## `system.time()`\n\nAltenatively, the `system.time()` function can be used to time the evaluation of a specific expression,\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/systemtime_46ec9c93364c067ef80cd7bdbffa9b68'}\n\n```{.r .cell-code}\nsystem.time(x_vec <- rnorm(100000) + 1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   user  system elapsed \n  0.003   0.000   0.002 \n```\n:::\n\n```{.r .cell-code}\nx_for <- numeric()\nsystem.time(\n\n  for (i in 1:100000){\n    x_for[i] <- rnorm(1) + 1\n  }\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   user  system elapsed \n  0.108   0.009   0.118 \n```\n:::\n:::\n\n\n## `microbenchmark` {.smaller}\n\nFinally, the `microbenchmark` package can be used to time functions repeatedly.\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/microbenchmark_ea2c13f560d2d14287414a1dc1608977'}\n\n```{.r .cell-code}\n# vectorized\nsq_vectorized <- function(x) {\n    return(x ^ 2)\n}\n# for loop\nsq_for_loop <- function(x) {\n    for (i in 1:length(x)) {\n        x[i] <- x[i] ^ 2\n    }\n    return(x)\n}\n\nlibrary(microbenchmark)\n# microbenchmark to compare the two functions\nx <- rnorm(1000)\ncompare_sq <- microbenchmark(sq_vectorized(x),\n                             sq_for_loop(x),\n                             times = 100)\ncompare_sq\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUnit: nanoseconds\n             expr   min    lq     mean median    uq     max neval\n sq_vectorized(x)   574   615  5870.79    656   738  517502   100\n   sq_for_loop(x) 26691 26855 42603.92  26896 27060 1527578   100\n```\n:::\n:::\n\n\n## Algorithmic efficiency\n\nThe amount of time code takes is related to the efficiency of the underlying algorithm.\n\nAlgorithms are commonly analyzed in terms of their asymptotic complexity. The most common way to describe complexity is Big O notation, where an algorithm with $O(g(n))$ complexity has a time requirement which is asymptotically proportional to $g(n)$.\n\nExamples:\n\n-   Finding the median in a sorted list of numbers is $O(1)$ constant complexity.\n\n-   Finding the largest number in an unsorted list of numbers is $O(n)$ linear complexity.\n\n## Example: inverting matrices.\n\nIn practice, timing code can be used to examine these relationships.\n\n\n::: {.cell hash='18_more-simulations_cache/revealjs/inversion_b72712dd7f5d83e0c53f7afdc3629f7e'}\n\n```{.r .cell-code}\ncompare_mat <- \n  microbenchmark(\n    mat_3_x_3 = solve(matrix(rnorm(9), nrow = 3)),\n    mat_5_x_5 = solve(matrix(rnorm(25), nrow = 5)),\n    mat_7_x_7 = solve(matrix(rnorm(49), nrow = 7)),\n    mat_9_x_9 = solve(matrix(rnorm(81), nrow = 9)),\n    times = 100\n  )\ncompare_mat\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nUnit: microseconds\n      expr    min      lq     mean  median      uq      max neval\n mat_3_x_3  6.601  7.0930  7.47143  7.3390  7.6260   15.047   100\n mat_5_x_5  7.503  7.9950  9.08191  8.2820  8.9380   50.512   100\n mat_7_x_7  8.815  9.2455  9.94455  9.6965 10.1680   18.655   100\n mat_9_x_9 10.332 10.8650 70.48310 11.5005 12.4435 5861.155   100\n```\n:::\n:::\n\n\n## \n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}