{
  "hash": "07bcc6a37d9cd09d39b2b2cc87714c90",
  "result": {
    "markdown": "---\ntitle: \"MATH167R: Sampling distributions\"\nauthor: \"Peter Gao\"\nformat: \n  revealjs:\n    theme: [./slides.scss, ../theme.scss]\neditor: visual\n---\n\n\n\n## Overview of today\n\n- anova\n- Chi squared tests\n\n## Sampling distributions\n\nWithout explicitly saying so, we have been simulating sampling distributions during our simulations.\n\nRecall: A sampling distribution is the probability distribution of a sample-based statistic.\n\nExample: If $X_1,\\ldots, X_{100}$ are iid random variables with variance $1$, what is the distribution of the sample mean $\\overline{X}$?\n\n## Simulating a sampling distribution\n\nExample simulation: Suppose $X_1,\\ldots, X_{100}\\sim N(0,1)$.\n\n\n\n::: {.cell hash='27_cross-validation_cache/html/sample_mean_6521a1d1de8315340c2511adcbe781e8'}\n\n```{.r .cell-code}\nset.seed(123)\nXbar <- replicate(10000, mean(rnorm(100)))\nhist(Xbar, main = \"Sampling distribution of mean of 100 N(0, 1) variables\")\n```\n\n::: {.cell-output-display}\n![](27_cross-validation_files/figure-html/sample_mean-1.png){width=672}\n:::\n:::\n\n\n\n## Simulating a sampling distribution\n\nWhat if $X_1,\\ldots, X_{100}\\sim \\mathrm{Exp}(1)$?\n\n\n\n::: {.cell hash='27_cross-validation_cache/html/sample_mean_exp_e99b690935b372f6c251114879e45539'}\n\n```{.r .cell-code}\nset.seed(123)\nXbar <- replicate(10000, mean(rexp(100, rate = 1)))\nhist(Xbar, main = \"Sampling distribution of mean of 100 Exponential(1) variables\")\n```\n\n::: {.cell-output-display}\n![](27_cross-validation_files/figure-html/sample_mean_exp-1.png){width=672}\n:::\n:::\n\n\n\n## Simulating a sampling distribution\n\nWhat if $X_1,\\ldots, X_{100}\\sim \\mathrm{Poisson}(1)$?\n\n\n\n::: {.cell hash='27_cross-validation_cache/html/sample_mean_pois_f95baaab01399f5620758f42dca47129'}\n\n```{.r .cell-code}\nset.seed(123)\nXbar <- replicate(10000, mean(rpois(100, lambda = 1)))\nhist(Xbar, main = \"Sampling distribution of mean of 100 Poisson(1) variables\")\n```\n\n::: {.cell-output-display}\n![](27_cross-validation_files/figure-html/sample_mean_pois-1.png){width=672}\n:::\n:::\n\n\n\n## Simulating a sampling distribution\n\nBy the central limit theorem, all of these sampling distributions are asymptotically Gaussian with variance 1 (though the mean values differ between the three). Since $n=100$ is fairly large (for these examples), all of the previous examples are close to Gaussian.\n\nWhat about if $n$ is smaller? Or if we consider other distributions?\n\nSimulation is a powerful strategy for testing out methods:\n\n-   Suppose you wish to know... is $n$ large?\n-   Create a simulation that generates data that looks like your real world data.\n-   Evaluate whether the results are reasonable/accurate using simulated data.\n\n## Smaller sample sizes\n\n\n\n::: {.cell hash='27_cross-validation_cache/html/smaller_sample_e9730dfaab8b9029d6b1043e53d0e1b7'}\n\n```{.r .cell-code}\nset.seed(123)\nXbar_normal <- replicate(10000, mean(rnorm(10)))\nXbar_exp <- replicate(10000, mean(rexp(10, rate = 1)))\nXbar_poisson <- replicate(10000, mean(rpois(10, lambda = 1)))\npar(mfrow = c(1, 3))\nhist(Xbar_normal, main = \"N(0, 1)\")\nhist(Xbar_exp, main = \"Exp(1)\")\nhist(Xbar_poisson, main = \"Poisson(1)\")\n```\n\n::: {.cell-output-display}\n![](27_cross-validation_files/figure-html/smaller_sample-1.png){width=672}\n:::\n:::\n\n\n\n## Other statistics\n\nWhat if we want the sampling distribution of the maximum? For each of these population models, the sampling distribution of the maximum is different.\n\n\n\n::: {.cell hash='27_cross-validation_cache/html/max_sampling_dist_40701da842f5ff88a91773cdef713b0b'}\n\n```{.r .cell-code}\nset.seed(123)\nXmax_normal <- replicate(10000, max(rnorm(10)))\nXmax_exp <- replicate(10000, max(rexp(10, rate = 1)))\nXmax_poisson <- replicate(10000, max(rpois(10, lambda = 1)))\npar(mfrow = c(1, 3))\nhist(Xmax_normal, main = \"N(0, 1)\")\nhist(Xmax_exp, main = \"Exp(1)\")\nhist(Xmax_poisson, main = \"Poisson(1)\")\n```\n\n::: {.cell-output-display}\n![](27_cross-validation_files/figure-html/max_sampling_dist-1.png){width=672}\n:::\n:::\n\n\n\n## Transformations\n\nWe can easily simulate sampling distributions for statistics summarizing the distribution of random variables that are defined as transformations of other random variables.\n\n\n\n::: {.cell hash='27_cross-validation_cache/html/mean_transformed_d3710ae85e10cc9ff074770806095061'}\n\n```{.r .cell-code}\nset.seed(123)\nXbar_normal <- replicate(10000, mean(rnorm(10) ^ 2))\nXbar_exp <- replicate(10000, mean(rexp(10, rate = 1) ^ 2))\nXbar_poisson <- replicate(10000, mean(rpois(10, lambda = 1) ^ 2))\npar(mfrow = c(1, 3))\nhist(Xbar_normal, main = \"N(0, 1) squared\")\nhist(Xbar_exp, main = \"Exp(1) squared\")\nhist(Xbar_poisson, main = \"Poisson(1) squared\")\n```\n\n::: {.cell-output-display}\n![](27_cross-validation_files/figure-html/mean_transformed-1.png){width=672}\n:::\n:::\n\n\n\n## Exercise\n\n-   Write code to create a histogram of the sampling distribution of the sample mean $\\overline{Y}$ of $Y_1,\\ldots, Y_{10}$ where $Y_i=\\sin(X_i)$ and $X_1,\\ldots, X_{10}$ are iid Uniform(0, 1) random variables.\n\n## Resampling methods\n\nThe previous simulations are all based on parametric models (normal, exponential, Poisson). However, we can also simulate sampling distributions without parametric assumptions on the data generating mechanism.\n\nSuppose we know $X_1,\\ldots, X_{20}\\sim \\mathrm{Exp}(1)$. The sampling distribution can be simulated as follows:\n\n\n\n::: {.cell hash='27_cross-validation_cache/html/exp_samp_dist_fc5b492c37dd4d5ed9f9117f8bcd8eeb'}\n\n```{.r .cell-code}\nset.seed(123)\nXbar_exp <- replicate(10000, mean(rexp(20, rate = 1)))\nhist(Xbar_exp)\n```\n\n::: {.cell-output-display}\n![](27_cross-validation_files/figure-html/exp_samp_dist-1.png){width=672}\n:::\n:::\n\n\n\n## Resampling methods\n\nWhat if we observe $X_1,\\ldots, X_{20}$, but we don't know that $X_i$ is exponentially distributed? We could just try the normal approximation to approximate the sampling distribution:\n\n\n\n::: {.cell hash='27_cross-validation_cache/html/exp_samp_dist_2_62c8ae17b307a30981975f34dbdf9fde'}\n\n```{.r .cell-code}\nX <- rexp(20, rate = 1)\nx_axis <- seq(0, 3, length.out = 1000)\n\n# plot \"true\" simulated sampling distribution\nhist(Xbar_exp, freq = F, ylim = c(0, 3))\n\n# plot normal theory\nlines(x_axis, dnorm(x_axis, mean = mean(X), sd = sd(X) / sqrt(20)), col = 'red')\n```\n\n::: {.cell-output-display}\n![](27_cross-validation_files/figure-html/exp_samp_dist_2-1.png){width=480}\n:::\n:::\n\n\n\n## Bootstrap samples\n\nBootstrapping is a resampling method that uses random samples with replacement from the sample data to approximate the sampling distribution of sample-based statistics.\n\n\n\n::: {.cell hash='27_cross-validation_cache/html/exp_samp_dist_3_b15792f5fc7f4ae9dc79c29655c44fb8'}\n\n```{.r .cell-code}\nprint(sort(X))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.00816693 0.06263315 0.11949335 0.12600941 0.14474580 0.14660666\n [7] 0.15582213 0.17485277 0.23514296 0.35492087 0.48980207 0.52215538\n[13] 0.72200938 1.27034542 1.56551624 1.74866229 1.82459209 1.84311722\n[19] 2.14225230 2.24995288\n```\n:::\n\n```{.r .cell-code}\n# sample with replacement from X\nX_resample <- sample(X, size = 20, replace = TRUE)\nprint(sort(X_resample))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1] 0.06263315 0.11949335 0.11949335 0.11949335 0.11949335 0.12600941\n [7] 0.14474580 0.14474580 0.15582213 0.15582213 0.17485277 0.35492087\n[13] 0.35492087 0.48980207 0.72200938 0.72200938 1.56551624 2.14225230\n[19] 2.24995288 2.24995288\n```\n:::\n:::\n\n\n\n## Bootstrap samples\n\nWe can repeatedly resample from $X$, then compute the resample sample means and plot the distribution:\n\n\n\n::: {.cell hash='27_cross-validation_cache/html/exp_samp_dist_4_3607489e5be184aa05acb38e171f7895'}\n\n```{.r .cell-code}\nbootstrap_Xbar <- replicate(10000, mean(sample(X, size = 20, replace = TRUE)))\nhist(bootstrap_Xbar)\n```\n\n::: {.cell-output-display}\n![](27_cross-validation_files/figure-html/exp_samp_dist_4-1.png){width=672}\n:::\n:::\n\n\n\n## Bootstrap samples\n\nWe can compare the bootstrap sampling distributions and true sampling distributions. In this case, the bootstrap does not seem that different from the normal approximation.\n\n\n\n::: {.cell hash='27_cross-validation_cache/html/exp_samp_dist_5_3d2652cc7f1d1dd4dd20b2e92bcfad43'}\n\n```{.r .cell-code}\nlibrary(ggplot2)\nplot_dat <-\n  data.frame(Xbar = c(Xbar_exp, bootstrap_Xbar),\n             source = rep(c(\"Parametric (Exp)\", \"Bootstrap\"), each = 10000))\nggplot(plot_dat, aes(x = Xbar, color = source)) +\n  geom_density() +\n  geom_function(fun = dnorm, \n                args = list(mean = mean(X), sd = sd(X) / sqrt(20)),\n                aes(color = \"Parametric (Normal)\")) \n```\n\n::: {.cell-output-display}\n![](27_cross-validation_files/figure-html/exp_samp_dist_5-1.png){width=672}\n:::\n:::\n\n\n\n## Bootstrap confidence intervals\n\nWe can take appropriate quantiles of the bootstrap samples to construct a bootstrap confidence interval using the `quantile()` function:\n\n\n\n::: {.cell hash='27_cross-validation_cache/html/exp_samp_dist_6_9df2e9b7131cfcac8a228f404dba5153'}\n\n```{.r .cell-code}\nquantile(bootstrap_Xbar, probs = c(.025, .975))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n    2.5%    97.5% \n0.467759 1.157051 \n```\n:::\n:::\n\n\n\n## Why bootstrap?\n\nIn this case, inference based on bootstrapping does not seem better than the normal approximation based on the central limit theorem.\n\nHowever, for many cases, we may not have a simple parametric approximation to the true sampling distribution. For example, suppose we wish to compute the sampling distribution of the sample median.\n\nNote however that the bootstrap may not work well for all statistics, such as the minimum (why not?).\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}