---
title: "MATH167R: Hypothesis Testing"
author: "Peter Gao"
format: 
  revealjs:
    theme: [./slides.scss, ../theme.scss]
editor: visual
---

## Overview of today

-   Simulations for power analysis
-   P-hacking simulations

## Designing your own hypothesis test

First, load the flips using the following code.

```{r load_flips_dummy}
#| echo: true
#| eval: true
#| cache: true
#| message: false
#| warning: false
#| fig-width: 6
#| fig-height: 5
#| out.width: "70%"
#| fig.align: "center"
#| fig-cap: ""
library(tidyverse)
flips <- read_csv("https://math167r-s24.github.io/static/flips.csv")
head(flips)
```

Can you tell which is real and which are fake?



## Visual inspection

```{r visualize_flips}
#| echo: false
#| eval: true
#| cache: true
#| message: false
#| warning: false
#| fig-width: 8
#| fig-height: 5
#| out.width: "100%"
#| fig.align: "center"
#| fig-cap: ""
flips_long <- flips |>
  mutate(id = 1:200) |>
  pivot_longer(-id,  names_to = "Sequence", values_to = "Flip")

flips_long |> 
  ggplot(aes(x = id, y = Flip, group = Sequence)) +
  geom_line() +
  geom_point(aes(color = Flip)) +
  facet_grid(rows = vars(Sequence)) + 
  theme(
    legend.position = "none",
    axis.title = element_blank()
  )
```


## Visual inspection

```{r visualize_flips_dummy}
#| echo: true
#| eval: false
#| cache: true
#| message: false
#| warning: false
#| fig-width: 8
#| fig-height: 5
#| out.width: "100%"
#| fig.align: "center"
#| fig-cap: ""
flips_long <- flips |>
  mutate(id = 1:200) |>
  pivot_longer(-id,  names_to = "Sequence", values_to = "Flip")

flips_long |> 
  ggplot(aes(x = id, y = Flip, group = Sequence)) +
  geom_line() +
  geom_point(aes(color = Flip)) +
  facet_grid(rows = vars(Sequence)) + 
  theme(
    legend.position = "none",
    axis.title = element_blank()
  )
```


## A slightly different test: streak length

We can also consider a different test statistic: longest streak.

```{r streaks}
#| echo: true
#| eval: true
#| cache: true
#| message: false
#| warning: false
#| fig-width: 8
#| fig-height: 5
#| out.width: "100%"
#| fig.align: "center"
#| fig-cap: ""
flip_streaks <- flips_long |>
  group_by(Sequence) |>
  summarize(longest_streak = max(rle(Flip)$length))
flip_streaks
```

## A slightly different test: streak length

We can then simulate the null distribution of streak length.

```{r streaks_sim_dummy}
#| echo: true
#| eval: false
#| cache: true
#| message: false
#| warning: false
#| fig-width: 8
#| fig-height: 5
#| out.width: "100%"
#| fig.align: "center"
#| fig-cap: ""
#| 
sim_streaks <- 
  data.frame(
    x = replicate(10000, 
                  max(rle(sample(c("H", "T"), size = 200, replace = T))$length)
    )
  )
ggplot() +
  geom_histogram(data = sim_streaks, aes(x = x), binwidth = 1) +
  geom_vline(data = flip_streaks,
             aes(color = Sequence, xintercept = longest_streak)) +
  xlab("Longest streak")
```

## Permutation tests

Typically, for hypothesis testing, we need to know the sampling distribution of the test statistic when the null hypothesis is true.

In some cases, we can derive the null sampling distribution analytically.

**What if we don't know the sampling distribution under the null?** A permutation test is simple way to estimate the sampling distribution for any test statistic, requiring only some exchangeability assumptions on the data.

## Permutation tests

**Example:** Suppose we want to understand whether carrying a particular genetic variant affects an individual's height $y$.

```{r}
#| eval: true
#| echo: true
carrier <- rep(c(0,1), c(100,200))

# an example where y is independent of the gene
null_y <- rnorm(300) 
# an example where y is dependent on the gene
alt_y <- rnorm(300, mean = carrier * 5) 
```

## Permutation tests

If the null hypothesis is true, the distribution of $Y$ for the carriers should look the same as the distribution for the non-carriers. If we **permute** the labels repeatedly, we can get resampled datasets.

If the null hypothesis is true, the shuffled data sets will resemble the original dataset. If the null hypothesis is false, the shuffled dataset may not look like the real data.

## Null hypothesis true

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(ggplot2)
data_dat <- data.frame(carrier = carrier, 
                       y = null_y) |>
  arrange(carrier, y) |>
  mutate(id = 1:length(carrier)) |>
  pivot_longer(cols = c("carrier", "y"), names_to = "Variable", values_to = "Value") |>
  group_by(Variable) |>
  mutate(Value = (Value - min(Value)) / (max(Value) - min(Value))) |>
  ungroup() |>
  mutate(label = "Data")
shuffle_dat <- data_dat |>
  group_by(Variable) |>
  mutate(Value = ifelse(Variable == "y", sample(Value), Value)) |>
  mutate(label = "Shuffled")
reorder_dat <- shuffle_dat |>
  pivot_wider(names_from = "Variable", values_from = "Value") |>
  arrange(carrier, y) |>
  mutate(id = 1:length(carrier)) |>
  pivot_longer(cols = c("carrier", "y"), names_to = "Variable", values_to = "Value") |>
  mutate(label = "Shuffled and reordered")
  
plot_dat <- bind_rows(data_dat, shuffle_dat, reorder_dat)

ggplot(plot_dat, aes(x = Variable, y = id, fill = Variable)) + 
  geom_tile(aes(alpha = Value)) +
  facet_wrap(~label,) +
  theme_bw() + 
  theme(legend.position = "none", 
        axis.text.y = element_blank(), 
        axis.text.x = element_text(size = 16), 
        strip.text = element_text(size = 16)) +
  ylab("") 

```

## Null hypothesis false

```{r}
#| eval: true
#| echo: false
#| message: false
#| warning: false
library(tidyverse)
library(ggplot2)
data_dat <- data.frame(carrier = carrier, 
                       y = alt_y) |>
  arrange(carrier, y) |>
  mutate(id = 1:length(carrier)) |>
  pivot_longer(cols = c("carrier", "y"), names_to = "Variable", values_to = "Value") |>
  group_by(Variable) |>
  mutate(Value = (Value - min(Value)) / (max(Value) - min(Value))) |>
  ungroup() |>
  mutate(label = "Data")
shuffle_dat <- data_dat |>
  group_by(Variable) |>
  mutate(Value = ifelse(Variable == "y", sample(Value), Value)) |>
  mutate(label = "Shuffled")
reorder_dat <- shuffle_dat |>
  pivot_wider(names_from = "Variable", values_from = "Value") |>
  arrange(carrier, y) |>
  mutate(id = 1:length(carrier)) |>
  pivot_longer(cols = c("carrier", "y"), names_to = "Variable", values_to = "Value") |>
  mutate(label = "Shuffled and reordered")
  
plot_dat <- bind_rows(data_dat, shuffle_dat, reorder_dat)

ggplot(plot_dat, aes(x = Variable, y = id, fill = Variable)) + 
  geom_tile(aes(alpha = Value)) +
  facet_wrap(~label) +
  theme_bw() + 
  theme(legend.position = "none", 
        axis.text.y = element_blank(), 
        axis.text.x = element_text(size = 16), 
        strip.text = element_text(size = 16)) +
  ylab("") 

```

## Permutation tests

1.  Calculate a test statistic based on the observed data.
2.  Repeatedly permute the group labels to create resamples. For each resample, compute the resample test statistic.
3.  Compare the observed data test statistic with the distribution of resampled test statistics.

## Permutation tests

In the case of our simulated data, we know the true distribution of the difference of sample means. We can thus use a $t$-test to perform our hypothesis test:

```{r}
#| eval: true
#| echo: true
t.test(null_y[carrier == 0], null_y[carrier == 1], var.equal=TRUE)
```

## Permutation tests

Compare with the $t$-test for the alternative hypothesis data:

```{r}
#| eval: true
#| echo: true
t.test(alt_y[carrier == 0], alt_y[carrier == 1], var.equal=TRUE)
```

## Permutation tests

For now, though, let's pretend we don't know the true null sampling distribution of our test statistic.

```{r}
#| eval: true
#| echo: true
set.seed(1)
null_diff <- mean(null_y[carrier==1]) - mean(null_y[carrier==0])
single_test <- function(label, y) {
  resample <- sample(label)
  # resample test statistic
  mean(y[resample == 1]) - mean(y[resample == 0])
}
test_stats_null <- replicate(1000, single_test(carrier, null_y))
```

## Permutation tests

```{r}
#| eval: true
#| echo: true
hist(test_stats_null)
abline(v = null_diff, lwd=2, col="purple")
mean(abs(test_stats_null) > abs(null_diff)) # P-value
```

## Permutation tests

Compare with the case where the null hypothesis is false.

```{r}
#| eval: true
#| echo: true
set.seed(1)
alt_diff <- mean(alt_y[carrier==1]) - mean(alt_y[carrier==0])
test_stats_alt <- replicate(1000, single_test(carrier, alt_y))
hist(test_stats_alt, xlim = c(-0.5, 6))
abline(v = alt_diff, lwd=2, col="purple")
mean(abs(test_stats_alt) > abs(alt_diff)) # P-value
```

## Permutation tests: `sleep` data

What if we apply this idea to the `sleep` data?

```{r}
#| eval: true
#| echo: true
head(sleep)
```


## Permutation tests: `sleep` data

```{r}
#| eval: true
#| echo: true
test_stat <- mean(sleep$extra[sleep$group == 1]) - 
  mean(sleep$extra[sleep$group == 2])
single_test <- function(label, y) {
  resample <- sample(label)
  # resample test statistic
  mean(y[resample == 1]) - mean(y[resample == 2])
}
test_stats_alt <- replicate(1000, single_test(sleep$group, sleep$extra))
hist(test_stats_alt)
abline(v = test_stat, lwd=2, col="purple")
mean(abs(test_stats_alt) > abs(test_stat)) # P-value
```

## Power analysis

Recall that the power of a hypothesis test is the probability of rejecting the null hypothesis when the null hypothesis is false.

Note the power will depend on the size of the difference between the true sampling distribution and the null hypothesis sampling distribution.

## One sample $z$-test

Suppose that $X_1,\ldots, X_n\sim N(\mu, 1)$.

Consider the hypotheses $H_0:\mu=0$ and $H_a:\mu\neq 0$.

We reject at the $\alpha$ significance level if $$|\overline{X}_n| > \frac{z_{\alpha/2}}{\sqrt{n}}$$

If $\mu=\mu_a\neq 0$, then $$\overline{X}_n\sim N\left(\mu_a, \frac{1}{\sqrt{n}}\right)$$

## One sample $z$-test

$$
\begin{align}
P\left(|\overline{X}_n| > \frac{z_{\alpha/2}}{\sqrt{n}}\right)&=P\left(\overline{X}_n> \frac{z_{\alpha/2}}{\sqrt{n}}\right) + P\left(\overline{X}_n < -\frac{z_{\alpha/2}}{\sqrt{n}}\right)\\
&=P\left(\frac{\overline{X}_n-\mu_a}{1/\sqrt{n}}> z_{\alpha/2}-\frac{\mu_a}{1/\sqrt{n}}\right) \\
&+ P\left(\frac{\overline{X}_n-\mu_a}{1/\sqrt{n}}<-z_{\alpha/2}-\frac{\mu_a}{1/\sqrt{n}}\right)\\
&=\left(1-\Phi\left(z_{\alpha/2}-\frac{\mu_a}{1/\sqrt{n}}\right)\right)+\Phi\left(-z_{\alpha/2}-\frac{\mu_a}{1/\sqrt{n}}\right)
\end{align}
$$

## One sample $z$-test

```{r}
#| eval: false
#| echo: true
one_sample_z_power <- function(mu_a, alpha, n) {
  z <- qnorm(1 - alpha / 2)
  return(1 - pnorm(z - mu_a * sqrt(n)) + pnorm(-z - mu_a * sqrt(n)))
}

# plot the power function
x <- data.frame(x = seq(-3, 3, length.out = 1000))
ggplot(x, aes(x = x)) + 
  geom_function(fun = one_sample_z_power, 
                aes(color = "n = 5"),
                args = list(alpha = .05, n = 5)) +
  geom_function(fun = one_sample_z_power, 
                aes(color = "n = 10"),
                args = list(alpha = .05, n = 10)) +
  geom_function(fun = one_sample_z_power, 
                aes(color = "n = 20"),
                args = list(alpha = .05, n = 20)) +
  xlab("True population mean") + ylab("Power") +
  theme_bw()
```

## One sample $z$-test

```{r}
#| eval: true
#| echo: false
one_sample_z_power <- function(mu_a, alpha, n) {
  z <- qnorm(1 - alpha / 2)
  return(1 - pnorm(z - mu_a * sqrt(n)) + pnorm(-z - mu_a * sqrt(n)))
}

# plot the power function
mu_a <- data.frame(mu_a = seq(-2.5, 2.5, length.out = 100))
ggplot(mu_a, aes(x = mu_a)) + 
  geom_function(fun = one_sample_z_power, 
                aes(color = "n = 5"),
                args = list(alpha = .05, n = 5)) +
  geom_function(fun = one_sample_z_power, 
                aes(color = "n = 10"),
                args = list(alpha = .05, n = 10)) +
  geom_function(fun = one_sample_z_power, 
                aes(color = "n = 20"),
                args = list(alpha = .05, n = 20)) +
  xlab("True population mean") + ylab("Power") +
  theme_bw()
```

## Using simulations to estimate power

```{r power.sim}
#| eval: false
#| echo: true
#| cache: true
simulate_test <- function(mu_a, alpha, n) {
  Xbar <- mean(rnorm(n, mean = mu_a, sd = 1))
  Z_score <- Xbar * sqrt(n)
  return(abs(Z_score) > qnorm(1 - alpha / 2))
}
power_sim <- function(mu_a, alpha, n) {
  return(mean(replicate(1000, simulate_test(mu_a, alpha, n))))
}

mu_a <- data.frame(mu_a = seq(-2.5, 2.5, length.out = 100))
sample_sizes <- c(5, 10, 20)

# matrix of simulation results
sim_results <- 
  sapply(sample_sizes,
         function(n) 
           sapply(mu_a$mu_a, 
                  function(mu)
                    power_sim(mu, .05, n)))

ggplot(mu_a, aes(x = mu_a)) +
  geom_line(aes(y = sim_results[, 1], color = "n = 5")) +
  geom_line(aes(y = sim_results[, 2], color = "n = 10")) +
  geom_line(aes(y = sim_results[, 3], color = "n = 20")) +
  xlab("True population mean") + ylab("Power") +
  theme_bw()
```

## Using simulations to estimate power

```{r power.sim.eval}
#| eval: true
#| echo: false
#| cache: true
simulate_test <- function(mu_a, alpha, n) {
  Xbar <- mean(rnorm(n, mean = mu_a, sd = 1))
  Z_score <- Xbar * sqrt(n)
  return(abs(Z_score) > qnorm(1 - alpha / 2))
}
power_sim <- function(mu_a, alpha, n) {
  return(mean(replicate(1000, simulate_test(mu_a, alpha, n))))
}

mu_a <- data.frame(mu_a = seq(-3, 3, length.out = 100))
sample_sizes <- c(5, 10, 20)

# matrix of simulation results
sim_results <- 
  sapply(sample_sizes,
         function(n) 
           sapply(mu_a$mu_a, 
                  function(mu)
                    power_sim(mu, .05, n)))

ggplot(mu_a, aes(x = mu_a)) +
  geom_line(aes(y = sim_results[, 1], color = "n = 5")) +
  geom_line(aes(y = sim_results[, 2], color = "n = 10")) +
  geom_line(aes(y = sim_results[, 3], color = "n = 20")) +
  xlab("True population mean") + ylab("Power") +
  theme_bw()
```


## Exercise: estimating power

If $X_1,\ldots X_n\sim N(1, 1)$, what is the power for a one-sample $t$ test for the hypotheses $H_0:\mu = 0$ and $H_a:\mu\not=0$ if $n=30$?

Create a simulation to estimate the power.

## P-hacking simulations

**P-hacking** refers to the practice of repeatedly performing hypothesis tests (and potentially manipulating the data) until a statistically significant P-values is obtained. Usually, only this final result is published, without mentioning all of the manipulations that came before.

## P-hacking simulations

Suppose we simulate 25 observations of 8 variables which we know to be uncorrelated.

```{r phack.sim, eval = F, echo = T}
#| eval: true
#| echo: true
no_signal_data <- matrix(rnorm(200), ncol = 8) # 25 x 8 matrix
pairs(no_signal_data) # pairwise scatter plots
```

## P-hacking simulations

```{r phack.sim.eval, eval = T, echo = F}
#| eval: true
#| echo: true
#| cache: true
no_signal_data <- matrix(rnorm(200), ncol = 8) # 25 x 8 matrix
pairs(no_signal_data) # pairwise scatter plots
```

## Multiple testing simulations

What if we perform a hypothesis test to test whether the correlation is zero between each pair of variables using `cor.test()`? With only 8 variables, we have 28 potential comparisons, the probability that we will (falsely) reject the null is already:

```{r comp}
#| eval: true
#| echo: true
#| cache: true
1 - (0.95) ^ 28
```

## Multiple testing simulations

```{r phack.sim.p}
#| eval: true
#| echo: true
#| cache: true
set.seed(1029)
no_signal_data<- matrix(rnorm(200), ncol = 8) # 25 x 8 matrix
pairs_to_compare <- combn(8, 2) # all combinations of 2 numbers from 1-8
p_values <- c()
for (i in 1:ncol(pairs_to_compare)) {
  index_1 <- pairs_to_compare[1, i]
  index_2 <- pairs_to_compare[2, i]
  test_res <- 
    cor.test(no_signal_data[, index_1],
             no_signal_data[, index_2])
  p_values <- c(p_values, test_res$p.value)
}
print(min(p_values))
```

## Multiple testing simulations

For this reason it is common to perform a correction to the p-values when many hypothesis tests are conducted.

**Example**: The Bonferroni correction divides $\alpha$ by the number of tests performed to get the corrected significance level.
